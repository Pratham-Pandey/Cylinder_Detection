{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c2554bc9",
   "metadata": {},
   "source": [
    "### Downloading Tenforflow Pre-Trained Model From Tensorflow Model Zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77464c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget, object_detection, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "253f308a",
   "metadata": {},
   "outputs": [],
   "source": [
    "CUSTOM_MODEL_NAME = 'custom_ssd_mobilenet' \n",
    "PRETRAINED_MODEL_NAME = 'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8'\n",
    "PRETRAINED_MODEL_URL = 'http://download.tensorflow.org/models/object_detection/tf2/20200711/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar.gz'\n",
    "TF_RECORD_SCRIPT_NAME = 'generate_tfrecord.py'\n",
    "LABEL_MAP_NAME = 'label_map.pbtxt'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "842f9381",
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = {\n",
    "    'WORKSPACE_PATH': os.path.join('Tensorflow', 'workspace'),\n",
    "    'SCRIPTS_PATH': os.path.join('Tensorflow','scripts'),\n",
    "    'APIMODEL_PATH': os.path.join('Tensorflow','models'),\n",
    "    'ANNOTATION_PATH': os.path.join('TensorFlow', 'workspace', 'Cylinder Detection','annotations'),\n",
    "    'IMAGE_PATH': os.path.join('Tensorflow', 'workspace','Cylinder Detection','images'),\n",
    "    'MODEL_PATH': os.path.join('Tensorflow', 'workspace','models'),\n",
    "    'PRETRAINED_MODEL_PATH': os.path.join('Tensorflow', 'workspace','Cylinder Detection','pre-trained-models'),\n",
    "    'CHECKPOINT_PATH': os.path.join('Tensorflow', 'workspace', 'Cylinder Detection','models',CUSTOM_MODEL_NAME), \n",
    "    'OUTPUT_PATH': os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'export'), \n",
    "    'TFJS_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfjsexport'), \n",
    "    'TFLITE_PATH':os.path.join('Tensorflow', 'workspace','models',CUSTOM_MODEL_NAME, 'tfliteexport'), \n",
    " }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c9b31e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {\n",
    "    'PIPELINE_CONFIG':os.path.join('TensorFlow', 'workspace','Cylinder Detection','models', CUSTOM_MODEL_NAME, 'pipeline.config'),\n",
    "    'TF_RECORD_SCRIPT': os.path.join(paths['SCRIPTS_PATH'], TF_RECORD_SCRIPT_NAME), \n",
    "    'LABELMAP': os.path.join(paths['ANNOTATION_PATH'], LABEL_MAP_NAME)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b8d942f3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8.tar (1).gz'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wget.download(PRETRAINED_MODEL_URL)      # Downloading the Pre-Trained Model                                     \n",
    "!move {PRETRAINED_MODEL_NAME+'.tar.gz'} {paths['PRETRAINED_MODEL_PATH']}     # Moving the Downloaded file to the 'Pre-Trained' Folder \n",
    "!cd {paths['PRETRAINED_MODEL_PATH']} && tar -zxvf {PRETRAINED_MODEL_NAME+'.tar.gz'}     # Extracting the File"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9db25154",
   "metadata": {},
   "source": [
    "### Image Annotation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "84e3d3a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "!labelimg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17f38c00",
   "metadata": {},
   "source": [
    "NOTE- Once the images are Anotated, they are moved to a 'train' and 'test folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b32dbaaa",
   "metadata": {},
   "source": [
    "### Creating Label Map  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e2d5f38a",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [{'name':'ThumbsUp', 'id':1}]\n",
    "\n",
    "with open(files['LABELMAP'], 'w') as f:\n",
    "    for label in labels:\n",
    "        f.write('item { \\n')\n",
    "        f.write('\\tname:\\'{}\\'\\n'.format(label['name']))\n",
    "        f.write('\\tid:{}\\n'.format(label['id']))\n",
    "        f.write('}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6466fae",
   "metadata": {},
   "source": [
    "### Generating TF Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "671effc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'train')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'train.record')} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f7361e0",
   "metadata": {},
   "source": [
    "NOTE - If the above command shows error, run it in cmd inside the script folder.\n",
    "\"python generate_tfrecord.py -x{'IMAGE Path'} -l{\"LABEL_MAP Path\"} -o{Annotations path with train.record'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "d5212c85",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python {files['TF_RECORD_SCRIPT']} -x {os.path.join(paths['IMAGE_PATH'], 'test')} -l {files['LABELMAP']} -o {os.path.join(paths['ANNOTATION_PATH'], 'test.record')} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642afc9e",
   "metadata": {},
   "source": [
    "NOTE - If the above command shows error, run it in cmd inside the script folder.\n",
    "\"python generate_tfrecord.py -x{'IMAGE Path'} -l{\"LABEL_MAP Path\"} -o{Annotations path with test.record'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec8d044a",
   "metadata": {},
   "source": [
    "### Extract the file of model which has been downloaded from Tensorflow Model Zoo and place the config folder to model  folder. Next we would update the model config as per the requiments."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc23b136",
   "metadata": {},
   "source": [
    "# Training the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26b355dd",
   "metadata": {},
   "source": [
    "To train the model we would first copy the 'model_main_tf2.py' file from 'TensorFlow/models/research/object_detection' and past it in the Current Project folder inside 'Workspace'."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fbfe205",
   "metadata": {},
   "source": [
    "Then we will cd to the main directory and execute the below command:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20f0c13",
   "metadata": {},
   "outputs": [],
   "source": [
    "python TensorFlow/models/research/object_detection/model_main_tf2.py --model_dir=TensorFlow/workspace/\"Cylinder Detection\"/models/custom_ssd_mobilenet --pipeline_config_path=TensorFlow/workspace/\"Cylinder Detection\"/models/custom_ssd_mobilenet/pipeline.config --num_train_steps=2000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60b72b16",
   "metadata": {},
   "source": [
    "This would train the model and the checkpoints created will be saved in custom model folder."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27328d3c",
   "metadata": {},
   "source": [
    "# Loading the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f7e21a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder\n",
    "from object_detection.utils import config_util\n",
    "import cv2\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "537fbb56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading config\n",
    "conf = config_util.get_configs_from_pipeline_file(files['PIPELINE_CONFIG'])\n",
    "my_model = model_builder.build(model_config=conf['model'], is_training=False)\n",
    "\n",
    "# Restoring Checkpoint\n",
    "cp = tf.compat.v2.train.Checkpoint(model=my_model)\n",
    "cp.restore(os.path.join(paths['CHECKPOINT_PATH'], 'ckpt-3')).expect_partial()\n",
    "\n",
    "@tf.function\n",
    "def detect_fn(image):\n",
    "    image, shapes = my_model.preprocess(image)\n",
    "    prediction_dict = my_model.predict(image, shapes)\n",
    "    detections = my_model.postprocess(prediction_dict, shapes)\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5492f3a4",
   "metadata": {},
   "source": [
    "# Detecting Cylinder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c480123f",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(files['LABELMAP'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3d5243c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(\"plant_2.mp4\")\n",
    "cap.set(3,1080)\n",
    "cap.set(4,720)\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "\n",
    "while cap.isOpened(): \n",
    "    ret, frame = cap.read()\n",
    "    frame = frame [50:1000, 50:1000]\n",
    "    image_np = np.array(frame)\n",
    "    \n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(image_np, 0), dtype=tf.float32)\n",
    "    detections = detect_fn(input_tensor)\n",
    "    \n",
    "    num_detections = int(detections.pop('num_detections'))\n",
    "    detections = {key: value[0, :num_detections].numpy()\n",
    "                  for key, value in detections.items()}\n",
    "    detections['num_detections'] = num_detections\n",
    "\n",
    "    # detection_classes should be ints.\n",
    "    detections['detection_classes'] = detections['detection_classes'].astype(np.int64)\n",
    "\n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = image_np.copy()\n",
    "\n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "                image_np_with_detections,\n",
    "                detections['detection_boxes'],\n",
    "                detections['detection_classes']+label_id_offset,\n",
    "                detections['detection_scores'],\n",
    "                category_index,\n",
    "                use_normalized_coordinates=True,\n",
    "                max_boxes_to_draw=5,\n",
    "                min_score_thresh=.8,\n",
    "                agnostic_mode=False)\n",
    "\n",
    "    cv2.imshow('object detection',  cv2.resize(image_np_with_detections, (800, 600)))\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        cap.release()\n",
    "        cv2.destroyAllWindows()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41e6df48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
